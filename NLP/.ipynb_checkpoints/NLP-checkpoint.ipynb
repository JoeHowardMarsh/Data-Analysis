{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d9dff4",
   "metadata": {},
   "source": [
    "# Uses of NLP:\n",
    "- Spell Checking\n",
    "- Keyword Search\n",
    "- Information Extraction\n",
    "- Advertisement Matching\n",
    "\n",
    "# Applications of NLP:\n",
    "- Sentimental analysis\n",
    "- Speech Recognition\n",
    "- Chat bots\n",
    "- Machine Translation\n",
    "\n",
    "# NLP Components:\n",
    "- Mapping input to useful representations\n",
    "- Analysing different aspects of the language\n",
    "- Text planning\n",
    "- Sentence Planning\n",
    "- Text Realization\n",
    "### NLG = Natural Language Generation\n",
    "### NLU = Natural Language Understanding\n",
    "\n",
    "# Ambiguity\n",
    "- Lexical Ambiguity\n",
    "- Syntactic Ambiguity\n",
    "- Referential Ambiguity\n",
    "\n",
    "## NLTK Library - Natural Language Tool Kit\n",
    "\n",
    "### Tokenization:\n",
    "- break a complex sentence into words\n",
    "- understand the importance of each of the wrods with respect to the sentence\n",
    "- produce a structural description of an input sentence\n",
    "\n",
    "\n",
    "## Edureka on freecodecamp video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5989dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries and retrieving data for nlp from github\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356f2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "# showing the data in the nltk library\n",
    "\n",
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d228d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cae91fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0177790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a79f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "# display the first 500 words of this text file 'hamlet'\n",
    "\n",
    "for word in hamlet[:500]:\n",
    "    print(word, sep=' ', end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7589768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my own example, wiki's definition of cryptocurrency\n",
    "\n",
    "cryptocurrency = 'A cryptocurrency, crypto-currency, or crypto is a binary data designed to work as a medium of exchange wherein individual coin ownership records are stored in a ledger existing in a form of a computerized database using strong cryptography to secure transaction records, to control the creation of additional coins, and to verify the transfer of coin ownership.[1][2] Some crypto schemes use validators to maintain the cryptocurrency. In a proof-of-stake model, owners put up their tokens as collateral. In return, they get authority over the token in proportion to the amount they stake. Generally, these token stakers get additional ownership in the token over time via network fees, newly minted tokens or other such reward mechanisms.[3] Cryptocurrency does not exist in physical form (like paper money) and is typically not issued by a central authority. Cryptocurrencies typically use decentralized control as opposed to a central bank digital currency (CBDC).[4] When a cryptocurrency is minted or created prior to issuance or issued by a single issuer, it is generally considered centralized. When implemented with decentralized control, each cryptocurrency works through distributed ledger technology, typically a blockchain, that serves as a public financial transaction database.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d9be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cryptocurrency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7201202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the tokenizer from the nltk library\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "486bccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'cryptocurrency',\n",
       " ',',\n",
       " 'crypto-currency',\n",
       " ',',\n",
       " 'or',\n",
       " 'crypto',\n",
       " 'is',\n",
       " 'a',\n",
       " 'binary',\n",
       " 'data',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'work',\n",
       " 'as',\n",
       " 'a',\n",
       " 'medium',\n",
       " 'of',\n",
       " 'exchange',\n",
       " 'wherein',\n",
       " 'individual',\n",
       " 'coin',\n",
       " 'ownership',\n",
       " 'records',\n",
       " 'are',\n",
       " 'stored',\n",
       " 'in',\n",
       " 'a',\n",
       " 'ledger',\n",
       " 'existing',\n",
       " 'in',\n",
       " 'a',\n",
       " 'form',\n",
       " 'of',\n",
       " 'a',\n",
       " 'computerized',\n",
       " 'database',\n",
       " 'using',\n",
       " 'strong',\n",
       " 'cryptography',\n",
       " 'to',\n",
       " 'secure',\n",
       " 'transaction',\n",
       " 'records',\n",
       " ',',\n",
       " 'to',\n",
       " 'control',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'additional',\n",
       " 'coins',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'verify',\n",
       " 'the',\n",
       " 'transfer',\n",
       " 'of',\n",
       " 'coin',\n",
       " 'ownership',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'Some',\n",
       " 'crypto',\n",
       " 'schemes',\n",
       " 'use',\n",
       " 'validators',\n",
       " 'to',\n",
       " 'maintain',\n",
       " 'the',\n",
       " 'cryptocurrency',\n",
       " '.',\n",
       " 'In',\n",
       " 'a',\n",
       " 'proof-of-stake',\n",
       " 'model',\n",
       " ',',\n",
       " 'owners',\n",
       " 'put',\n",
       " 'up',\n",
       " 'their',\n",
       " 'tokens',\n",
       " 'as',\n",
       " 'collateral',\n",
       " '.',\n",
       " 'In',\n",
       " 'return',\n",
       " ',',\n",
       " 'they',\n",
       " 'get',\n",
       " 'authority',\n",
       " 'over',\n",
       " 'the',\n",
       " 'token',\n",
       " 'in',\n",
       " 'proportion',\n",
       " 'to',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'they',\n",
       " 'stake',\n",
       " '.',\n",
       " 'Generally',\n",
       " ',',\n",
       " 'these',\n",
       " 'token',\n",
       " 'stakers',\n",
       " 'get',\n",
       " 'additional',\n",
       " 'ownership',\n",
       " 'in',\n",
       " 'the',\n",
       " 'token',\n",
       " 'over',\n",
       " 'time',\n",
       " 'via',\n",
       " 'network',\n",
       " 'fees',\n",
       " ',',\n",
       " 'newly',\n",
       " 'minted',\n",
       " 'tokens',\n",
       " 'or',\n",
       " 'other',\n",
       " 'such',\n",
       " 'reward',\n",
       " 'mechanisms',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'Cryptocurrency',\n",
       " 'does',\n",
       " 'not',\n",
       " 'exist',\n",
       " 'in',\n",
       " 'physical',\n",
       " 'form',\n",
       " '(',\n",
       " 'like',\n",
       " 'paper',\n",
       " 'money',\n",
       " ')',\n",
       " 'and',\n",
       " 'is',\n",
       " 'typically',\n",
       " 'not',\n",
       " 'issued',\n",
       " 'by',\n",
       " 'a',\n",
       " 'central',\n",
       " 'authority',\n",
       " '.',\n",
       " 'Cryptocurrencies',\n",
       " 'typically',\n",
       " 'use',\n",
       " 'decentralized',\n",
       " 'control',\n",
       " 'as',\n",
       " 'opposed',\n",
       " 'to',\n",
       " 'a',\n",
       " 'central',\n",
       " 'bank',\n",
       " 'digital',\n",
       " 'currency',\n",
       " '(',\n",
       " 'CBDC',\n",
       " ')',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'When',\n",
       " 'a',\n",
       " 'cryptocurrency',\n",
       " 'is',\n",
       " 'minted',\n",
       " 'or',\n",
       " 'created',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'issuance',\n",
       " 'or',\n",
       " 'issued',\n",
       " 'by',\n",
       " 'a',\n",
       " 'single',\n",
       " 'issuer',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'generally',\n",
       " 'considered',\n",
       " 'centralized',\n",
       " '.',\n",
       " 'When',\n",
       " 'implemented',\n",
       " 'with',\n",
       " 'decentralized',\n",
       " 'control',\n",
       " ',',\n",
       " 'each',\n",
       " 'cryptocurrency',\n",
       " 'works',\n",
       " 'through',\n",
       " 'distributed',\n",
       " 'ledger',\n",
       " 'technology',\n",
       " ',',\n",
       " 'typically',\n",
       " 'a',\n",
       " 'blockchain',\n",
       " ',',\n",
       " 'that',\n",
       " 'serves',\n",
       " 'as',\n",
       " 'a',\n",
       " 'public',\n",
       " 'financial',\n",
       " 'transaction',\n",
       " 'database',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing my word definition (cryptocurrency)\n",
    "\n",
    "cryptocurrency_tokens = word_tokenize(cryptocurrency)\n",
    "cryptocurrency_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6095b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cryptocurrency_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb50641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing distinct frequency - this allows us to find the frequency of particular words\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44843db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 13, ',': 12, '.': 9, 'to': 8, 'in': 7, 'the': 6, 'cryptocurrency': 5, 'or': 4, 'is': 4, 'as': 4, ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this counts the frequency of every word in the text\n",
    "\n",
    "for word in cryptocurrency_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c138a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the frequency of a particular word, 'coin' in this case\n",
    "\n",
    "fdist['coin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0edc5ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this shows the number of distinct tokens (words) in the text\n",
    "\n",
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8660a77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 13),\n",
       " (',', 12),\n",
       " ('.', 9),\n",
       " ('to', 8),\n",
       " ('in', 7),\n",
       " ('the', 6),\n",
       " ('cryptocurrency', 5),\n",
       " ('or', 4),\n",
       " ('is', 4),\n",
       " ('as', 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the most common words in the text (top 10 most common)\n",
    "\n",
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2113ab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the number of paragraphs that are separated by a new line in the text\n",
    "\n",
    "from nltk.tokenize import blankline_tokenize\n",
    "cryptocurrency_blank=blankline_tokenize(cryptocurrency)\n",
    "len(cryptocurrency_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1bdf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A cryptocurrency, crypto-currency, or crypto is a binary data designed to work as a medium of exchange wherein individual coin ownership records are stored in a ledger existing in a form of a computerized database using strong cryptography to secure transaction records, to control the creation of additional coins, and to verify the transfer of coin ownership.[1][2] Some crypto schemes use validators to maintain the cryptocurrency. In a proof-of-stake model, owners put up their tokens as collateral. In return, they get authority over the token in proportion to the amount they stake. Generally, these token stakers get additional ownership in the token over time via network fees, newly minted tokens or other such reward mechanisms.[3] Cryptocurrency does not exist in physical form (like paper money) and is typically not issued by a central authority. Cryptocurrencies typically use decentralized control as opposed to a central bank digital currency (CBDC).[4] When a cryptocurrency is minted or created prior to issuance or issued by a single issuer, it is generally considered centralized. When implemented with decentralized control, each cryptocurrency works through distributed ledger technology, typically a blockchain, that serves as a public financial transaction database.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a particular paragraph (only one in this case)\n",
    "\n",
    "cryptocurrency_blank[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97175fd",
   "metadata": {},
   "source": [
    "## Tokenization:\n",
    "#### Bigrams - tokens of 2 consecutive words\n",
    "#### Trigrams - tokens of 3 consecutive words\n",
    "#### Ngrams - tokens of any number of consecutive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b75e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c30fae2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', 'random', 'string', 'to', 'use', 'as', 'an', 'example']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this separates a string into individual words\n",
    "\n",
    "string = \"some random string to use as an example\"\n",
    "quote_tokens = nltk.word_tokenize(string)\n",
    "quote_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047e6f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('some', 'random'),\n",
       " ('random', 'string'),\n",
       " ('string', 'to'),\n",
       " ('to', 'use'),\n",
       " ('use', 'as'),\n",
       " ('as', 'an'),\n",
       " ('an', 'example')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this creates a list of all possible bigrams from the string above\n",
    "\n",
    "quotes_bigrams = list(nltk.bigrams(quote_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3717226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('some', 'random', 'string'),\n",
       " ('random', 'string', 'to'),\n",
       " ('string', 'to', 'use'),\n",
       " ('to', 'use', 'as'),\n",
       " ('use', 'as', 'an'),\n",
       " ('as', 'an', 'example')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same thing but for trigrams instead of bigrams\n",
    "\n",
    "quotes_trigrams = list(nltk.trigrams(quote_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e75efcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('some', 'random', 'string', 'to', 'use'),\n",
       " ('random', 'string', 'to', 'use', 'as'),\n",
       " ('string', 'to', 'use', 'as', 'an'),\n",
       " ('to', 'use', 'as', 'an', 'example')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same thing but for ngrams (any number of consecutive word combination)\n",
    "\n",
    "quotes_ngrams = list(nltk.ngrams(quote_tokens, 5))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd019315",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "#### - Stemming normalises words into its base form/root form\n",
    "#### e.g. affection, affected, affecting would all be based on root word form = affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f2c9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are different types of stemming - e.g. the PorterStemmer, the LancasterStemmer, the SnowballStemmer\n",
    "# first lets use the PorterStemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "445d7796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the stemming module to stem the word 'affection'\n",
    "\n",
    "pst.stem(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9650a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "# creating a list of words to stem each word in the list\n",
    "\n",
    "words_to_stem = ['give', 'giving', 'given', 'gave']\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2ca21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n"
     ]
    }
   ],
   "source": [
    "# now using the LancasterStemmer - we can see that this stemmer goes deeper into the root than the Porter stemmer\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst=LancasterStemmer()\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b0e9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "# now using the SnowballStemmer - with this stemmer, the natural language used must be specified! (english here)\n",
    "# similar to the Porterstemmer but uses different terms\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "sbst=SnowballStemmer('english')\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +sbst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239447e8",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "#### - Groups together different inflected forms of a word, called Lemma\n",
    "#### - Similar to stemming as it maps several words into one common root\n",
    "#### - Output of Lemmatisation is always a proper word\n",
    "#### - e.g. gone, going should be mapped to 'go'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c215d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the lemmatization module from the nltk library\n",
    "\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c6ebb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying it out on any given word\n",
    "\n",
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a10ec939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "# using it on our list of words\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfad62b",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "#### Stop words are the most common words that many search engines avoid for the purpose of saving space and time in\n",
    "#### processing large amounts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20859c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module for stopwords\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f5f46c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provides the list of stopwords included in the english language \n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "565ab8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many stop words are there in this module for the english language? 179\n",
    "\n",
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39077f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 13),\n",
       " (',', 12),\n",
       " ('.', 9),\n",
       " ('to', 8),\n",
       " ('in', 7),\n",
       " ('the', 6),\n",
       " ('cryptocurrency', 5),\n",
       " ('or', 4),\n",
       " ('is', 4),\n",
       " ('as', 4)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "377ee6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the compiler from the re module to create a string that matches any digit or special char\n",
    "\n",
    "import re\n",
    "punctuation=re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59e1049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a list of words from the text but excludes the punctuation specified above\n",
    "\n",
    "post_punctuation = []\n",
    "for words in cryptocurrency_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e11bf",
   "metadata": {},
   "source": [
    "## POS - Parts Of Speech\n",
    "#### - e.g. grammar, questions, verbs, adjectives, adverbs, nouns, pronouns, prepositions, passives, tenses, relatives etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d13a132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "# this lists the meaning of each 'part of speech' that's in the nltk library\n",
    "\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "909747fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenising this string 'sent' as an example\n",
    "\n",
    "sent = \"Lesley is a natural when it comes to drawing\"\n",
    "sent_tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d577563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lesley', 'NNP')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))\n",
    "    \n",
    "# as you can see it defines 'Timothy' as a noun, 'is' as a verb, 'a' as a determiner etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e9a14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Joe', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('eating', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('delicious', 'JJ')]\n",
      "[('cake', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# here's another example, this example shows an issue with the library, counts 'is' as a verb because it classifies 'is eating'\n",
    "# as a single tome\n",
    "\n",
    "sent2 = \"Joe is eating a delicious cake\"\n",
    "sent2_tokens = word_tokenize(sent2)\n",
    "for token in sent2_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a3704",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "#### movies, monetary value, organisation, location, quantities and people are all Named Entities.\n",
    "#### sometimes named entities are mis-classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cefb5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module used to classify named identities\n",
    "\n",
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f396807",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_sent = \"The UK Prime Minister stays in 10 DOWNING STREET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f69d67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenising the 'ne_sent' string and adding the pos tags\n",
    "\n",
    "ne_tokens = word_tokenize(ne_sent)\n",
    "ne_tags = nltk.pos_tag(ne_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15c32c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION UK/NNP)\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  10/CD\n",
      "  DOWNING/NNP\n",
      "  STREET/NNP)\n"
     ]
    }
   ],
   "source": [
    "ne_ner = ne_chunk(ne_tags)\n",
    "print(ne_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34a889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes the languages slightly easier to understand (it still thinks UK is an organisation but still)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f7b2d",
   "metadata": {},
   "source": [
    "## Syntax Tree\n",
    "#### a tree representation of syntactic structure of a sentence or string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff19824",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "#### Picking up individual pieces of information and grouping them into bigger pieces\n",
    "#### similar to the opposite of tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7edff688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('cat', 'NN'),\n",
       " ('ate', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('mouse', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('after', 'IN'),\n",
       " ('fresh', 'JJ'),\n",
       " ('cheese', 'NN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = \"The big cat ate the little mouse who was after fresh cheese\"\n",
    "new_tokens = nltk.pos_tag(word_tokenize(new))\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd53ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the grammar\n",
    "\n",
    "grammar_np = r\"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55285ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a regular expression parser to parse the grammar definition\n",
    "\n",
    "chunk_parser = nltk.RegexpParser(grammar_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac14c72f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                 subprocess.call(\n\u001b[0m\u001b[0;32m    817\u001b[0m                     [\n\u001b[0;32m    818\u001b[0m                         find_binary(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \"\"\"\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    856\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    859\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1309\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1312\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', [('The', 'DT'), ('big', 'JJ'), ('cat', 'NN')]), ('ate', 'VBD'), Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('mouse', 'NN')]), ('who', 'WP'), ('was', 'VBD'), ('after', 'IN'), Tree('NP', [('fresh', 'JJ'), ('cheese', 'NN')])])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_result = chunk_parser.parse(new_tokens)\n",
    "chunk_result\n",
    "\n",
    "# result looks like an error but it still works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
